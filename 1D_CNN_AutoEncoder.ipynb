{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1D-CNN_220610.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Vec5MZtm4-qAPj3coFsjWiZZXIWmzplp",
      "authorship_tag": "ABX9TyOiu/KEMMbimJp1yAf8weXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/torch_1D-CNN/blob/main/1D_CNN_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCZrz1gHn6rX"
      },
      "outputs": [],
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "#Data Load\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Batt/train_v.txt') \n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Batt/test_v.txt')\n",
        "df_train2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Batt/train_v.txt') \n",
        "train_data_input = df_train.iloc[:,:]\n",
        "train_data_output = df_train.iloc[:,:]\n",
        "test_data_input = df_test.iloc[:,:]\n",
        "test_data_output = df_test.iloc[:,:]\n",
        "print(train_data_input.shape,train_data_input)\n",
        "print(train_data_output.shape, train_data_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5T40TKOJyQCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time1 = 5500\n",
        "time2 = 5800\n",
        "#train_gan = df_train.iloc[0:len(df_train),-1]\n",
        "train_gan = df_train.iloc[time1:time2, :].values\n",
        "print(train_gan.shape)\n",
        "train_gan2 = df_test.iloc[time1:time2, :].values\n",
        "#train_gan2 = train_gan2.to_numpy()\n",
        "trainSet_for_result = df_train2.iloc[time1:time2,:].values\n",
        "print(train_gan)"
      ],
      "metadata": {
        "id": "LxyI8MMt0Pr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalization\n",
        "\n",
        "#print(\"Before Norm : \",train_data_input.shape, train_data_input)\n",
        "\n",
        "def origin_minmax(data) : \n",
        "  arr_max = np.zeros(data.shape[1])\n",
        "  arr_min = np.zeros(data.shape[1])\n",
        "  print(arr_min)\n",
        "  print(data.shape[1])\n",
        "  for i in range(data.shape[1]) : \n",
        "    print(i)\n",
        "    max = np.max(data[:,i])\n",
        "    min = np.min(data[:,i]) \n",
        "    arr_max[i] = max\n",
        "    arr_min[i] = min\n",
        "    pass\n",
        "  return arr_max, arr_min\n",
        "\n",
        "arr_max1, arr_min1 = origin_minmax(train_gan)\n",
        "arr_max2, arr_min2 = origin_minmax(train_gan2)\n",
        "#print(arr_max1, arr_min1)\n",
        "\n",
        "def MinMaxScaler(data):\n",
        "  for i in range(data.shape[1]) : \n",
        "    max = np.max(data[:,i])\n",
        "    min = np.min(data[:,i])\n",
        "    data[:,i] = (data[:,i] - min) / (max - min + 1e-7)\n",
        "    pass\n",
        "  return data\n",
        "\n",
        "train_gan = MinMaxScaler(train_gan)\n",
        "#train_gan2 = MinMaxScaler(train_gan2)\n",
        "\n",
        "def back_MinMax(data,max,min):\n",
        "  print(max)\n",
        "  print(min)\n",
        "  for i in range(data.shape[1]) : \n",
        "    data[:,i] = data[:,i] * (max[i] - min[i]) + min[i]\n",
        "    pass\n",
        "  return data\n",
        "\n",
        "#print(\"After Norm : \",train_gan.shape, train_gan)\n",
        "#print(\"After De_Norm : \",back_MinMax(train_gan, arr_max1, arr_min1))\n",
        "train_gan = torch.tensor([train_gan], dtype = torch.float32)\n",
        "train_gan2 = torch.tensor([train_gan2], dtype = torch.float32)\n",
        "print(train_gan)\n",
        "print(\"TrainSet for Result : \",trainSet_for_result)"
      ],
      "metadata": {
        "id": "lNF3xvHgqGhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Windowing for Sequence\n",
        "'''\n",
        "seq_length = 2\n",
        "\n",
        "def sliding_window(time_series, seq_length):\n",
        "    time_series = np.squeeze(time_series)\n",
        "    dataX = []\n",
        "    dataY = []\n",
        "    for i in range(0, int(len(time_series)/seq_length)): \n",
        "        _x = time_series[(i*seq_length):(i*seq_length) + seq_length, :]\n",
        "        _y = time_series[(i*seq_length):(i*seq_length) + seq_length, :]  # for AE\n",
        "        dataX.append(_x)\n",
        "        dataY.append(_y)\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "train_gan_window_X, train_gan_window_Y = sliding_window(train_gan, seq_length)\n",
        "test_gan_window_X, train_gan_window_Y = sliding_window(train_gan2, seq_length)\n",
        "\n",
        "train_gan_window_X = torch.tensor(train_gan_window_X)\n",
        "#print(train_gan_window_X.shape)\n",
        "#print(train_gan_window_Y.shape)\n",
        "\n",
        "train_gan_window_X = torch.tensor(train_gan_window_X, dtype = torch.float32)\n",
        "train_gan_window_Y = torch.tensor(train_gan_window_Y, dtype = torch.float32)\n",
        "\n",
        "print(train_gan.shape, train_gan)\n",
        "print(train_gan_window_X.shape, train_gan_window_X)\n",
        "'''"
      ],
      "metadata": {
        "id": "2Wf-5BRR0d-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_gan = train_gan.transpose(1,2)\n",
        "#train_gan2 = train_gan2.transpose(1,2)\n",
        "'''\n",
        "print(train_gan_window_X.shape) \n",
        "print(\"train_gan_window_X.shape[0] : \",train_gan_window_X.shape[0])\n",
        "print(\"train_gan_window_X.shape[1] : \",train_gan_window_X.shape[1])\n",
        "print(\"train_gan_window_X.shape[2] : \",train_gan_window_X.shape[2])\n",
        "'''"
      ],
      "metadata": {
        "id": "a5aIEGSfQDtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1D-CNN AE Class\n",
        "filters = 10\n",
        "kernel_size = 5\n",
        "padding_size = 2\n",
        "stride = 1\n",
        "\n",
        "class CNN(nn.Module): \n",
        "\n",
        "  def __init__(self) : \n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.a = nn.Conv1d(in_channels = seq_length, out_channels = filters, kernel_size = kernel_size, padding = padding_size, padding_mode = 'zeros')\n",
        "    self.b = nn.LeakyReLU(0.02)\n",
        "    self.c = nn.Linear(filters*5, 5*seq_length)\n",
        "    self.d = nn.Sigmoid()\n",
        "\n",
        "    self.loss_function = nn.MSELoss()\n",
        "    self.optimiser = torch.optim.Adam(self.parameters(), lr = 1e-3)\n",
        "    self.progress = []\n",
        "    pass\n",
        "\n",
        "  def forward(self, inputs) : \n",
        "     #simply run model\n",
        "      print(\"Inputs : \", inputs.shape)\n",
        "      x = self.a(inputs)\n",
        "      #print(\"A\", x.shape)\n",
        "      x = self.b(x)\n",
        "      #print(\"B\", x.shape)\n",
        "      x = torch.flatten(x)\n",
        "      #print(\"Flatten : \", x.shape)\n",
        "      x = self.c(x)\n",
        "      #print(\"C\", x.shape)\n",
        "      #x = x.reshape(5, seq_length)\n",
        "      x = x.reshape(seq_length, 5)\n",
        "      print(\"After reshape : \",x.shape)\n",
        "      x = self.d(x)\n",
        "      print(\"D_Final Output\", x)\n",
        "      return x\n",
        "\n",
        "  def train(self, inputs) :\n",
        "    self.optimiser.zero_grad()\n",
        "    #print(\"1\")\n",
        "    outputs = self.forward(inputs)\n",
        "    #print(\"2\")\n",
        "    #print(\"input : \",inputs)\n",
        "    #print(\"output : \",outputs.shape, outputs)\n",
        "    loss = self.loss_function(inputs, outputs)\n",
        "    #print(\"3\")\n",
        "    loss.backward()\n",
        "    #print('4')\n",
        "    self.optimiser.step()\n",
        "    #print(\"5\")\n",
        "\n",
        "  def plot_progress(self) : \n",
        "    df = pd.DataFrame(self.progress, columns = ['1D CNN AE Loss'])\n",
        "    df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "3NFRspbL2aUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs1 = 10\n",
        "epochs2 = 10\n",
        "D = CNN()\n",
        "seq_length = 3\n",
        "\n",
        "for j in range(epochs1) : \n",
        "  for i in range(int((time2-time1)/seq_length)) :\n",
        "    #refs = train_gan[0,:,i:i+seq_length]\n",
        "    refs = train_gan[0,i:i+seq_length,:]\n",
        "    #print(\"refs.shape : \",refs.shape) #[Features(5), Data_seq(3)]\n",
        "    #print(\" Training Input : \",refs)\n",
        "    for j in range(epochs2) : \n",
        "      D.train(refs)\n",
        "  pass\n",
        "  pass\n",
        "print(\"Percentage : \", j/epochs1 * 100, '%')\n",
        "pass"
      ],
      "metadata": {
        "id": "GS4-OEMiqHQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(int((time2-time1)/seq_length)-1) : \n",
        "  seed_test = train_gan[:, i:i+seq_length, :]\n",
        "  Real_Value = trainSet_for_result[i:i+seq_length,:]\n",
        "  #print(seed_test.shape)\n",
        "  out_test = D.forward(seed_test)\n",
        "  out_test = out_test.detach().cpu().numpy()\n",
        "  out_test = out_test.reshape([seq_length,5])\n",
        "  out_test = back_MinMax(out_test, arr_max1, arr_min1)\n",
        "  print(\"Generated Value : \", out_test)\n",
        "  print(\"Real Value : \", Real_Value)\n",
        "  print(\"                                   \")"
      ],
      "metadata": {
        "id": "-Qexcr2WI42d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainSet_for_result.shape)"
      ],
      "metadata": {
        "id": "DmNwDBqwX9F-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}